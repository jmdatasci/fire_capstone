{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main script to clean wind data at the zip code, monthly level\n",
    "\n",
    "Modules: N/A <br>\n",
    "Author: Cornelia Ilin <br>\n",
    "Email: cilin@wisc.edu <br>\n",
    "Date created: May 14, 2021 <br>\n",
    "\n",
    "**Citations (data sources)**\n",
    "\n",
    "``Wind data:`` \n",
    "\n",
    "download the \"MERRA2_100.tavgM_2d_slv_Nx\" product; this provides monthly averages of U and V components\n",
    "\n",
    "1. https://search.earthdata.nasa.gov/search/granules?p=C1276812859-GES_DISC&pg[0][qt]=1991-01-01T00%3A00%3A00.000Z%2C2017-12-31T23%3A59%3A59.999Z&pg[0][gsk]=-start_date&q=MERRA-2%20tavgM&tl=1624239533!3!!&m=-0.0703125!0.0703125!2!1!0!0%2C2\n",
    "\n",
    "__Jordan steps for wind data__ \n",
    "  * Search for report \"M2TMNXSLV\"\n",
    "  * Narrow down scope with geoshape file for CA (NOT ZCTA)  \n",
    "      * Acquired here https://data.ca.gov/dataset/ca-geographic-boundaries \n",
    "        * **No VPN access seems to be permitted here**\n",
    "  * Query for 1991-01-01 00:00:00 - Today  \n",
    "      * Click recurring\n",
    "\n",
    "and data dictionary here:\n",
    "\n",
    "2. https://gmao.gsfc.nasa.gov/pubs/docs/Bosilovich785.pdf\n",
    "3. https://disc.gsfc.nasa.gov/datasets/M2T1NXSLV_5.12.4/summary\n",
    "\n",
    "\n",
    "``Shapefiles for California ZIP codes (2010 census):``\n",
    "\n",
    "4. https://www.census.gov/cgi-bin/geo/shapefiles/index.php?year=2010&layergroup=ZIP+Code+Tabulation+Areas\n",
    "\n",
    "__Jordan tweaks__\n",
    "  * There is an updated 2020 and 2022 ZCTA file available but I think it makes sense to keep the 2010 as that is what project started with and shouldn't have changed much\n",
    "\n",
    "``Installation errors with Geopandas:``\n",
    "\n",
    "5. https://stackoverflow.com/questions/54734667/error-installing-geopandas-a-gdal-api-version-must-be-specified-in-anaconda\n",
    "\n",
    "``How to compute wind speed and direction:``\n",
    "\n",
    "6. https://stackoverflow.com/questions/21484558/how-to-calculate-wind-direction-from-u-and-v-wind-components-in-r\n",
    "7. https://github.com/blaylockbk/Ute_WRF/blob/master/functions/wind_calcs.py\n",
    "\n",
    "``Wind speed and direction intuition:``\n",
    "\n",
    "8. http://colaweb.gmu.edu/dev/clim301/lectures/wind/wind-uv\n",
    "9. https://www.earthdatascience.org/courses/use-data-open-source-python/intro-vector-data-python/spatial-data-vector-shapefiles/intro-to-coordinate-reference-systems-python/\n",
    "\n",
    "``To create maps of this wind data:``\n",
    "\n",
    "and also used to provide intuition for winddir and windspeed\n",
    "\n",
    "10. https://disc.gsfc.nasa.gov/information/howto?title=How%20to%20calculate%20and%20plot%20wind%20speed%20using%20MERRA-2%20wind%20component%20data%20using%20Python\n",
    "\n",
    "\n",
    "``Error - MultiPolygon or multipoly is not iterable``  \n",
    "\n",
    "This seems to come from an error in version of shapely. Force install with a version below 2.0, I use `shapely==1.8.5` in my env.\n",
    "\n",
    "\n",
    "**Citations (persons)**\n",
    "1. N/A\n",
    "\n",
    "**Preferred environment**\n",
    "1. Code written in Jupyter Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import netCDF4 as ncdf\n",
    "import os\n",
    "from datetime import date, timedelta\n",
    "from math import pi\n",
    "import fiona\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "# geography\n",
    "import geopandas as gpd\n",
    "import osmnx as ox\n",
    "import shapely\n",
    "from shapely.geometry import Point\n",
    "\n",
    "#Moved from sklearn.neighbors to sklearn.metrics following their package change\n",
    "import sklearn.metrics\n",
    "dist = sklearn.metrics.DistanceMetric.get_metric(\n",
    "    'haversine'\n",
    ")\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    'ignore'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Define working directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# in_dir_zip_shapes = 'C:/Users/cilin/Research/CA_hospitals/Input/raw_data/census_geo/shapefiles_zcta/'\n",
    "# in_dir = 'C:/Users/cilin/Research/CA_hospitals/Input/raw_data/winds/'\n",
    "# in_health = 'C:/Users/cilin/Research/CA_hospitals/Input/final_data/health/'\n",
    "# out_dir = 'C:/Users/cilin/Research/CA_hospitals/Input/final_data/winds/'\n",
    "\n",
    "#Local directories on my machine (not gdrive)\n",
    "in_dir_zip_shapes = '../data/raw/wind/tl_2010_06_zcta510/'\n",
    "in_dir_wind = '../data/raw/wind/ca only/'\n",
    "in_dir_fire = '../data/interim/'\n",
    "in_health = '../data/raw/health/'\n",
    "out_dir = '../data/processed/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 3: Define functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``read_clean wind``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fire_index</th>\n",
       "      <th>FIRE_NAME</th>\n",
       "      <th>ALARM_DATE</th>\n",
       "      <th>CONT_DATE</th>\n",
       "      <th>CAUSE</th>\n",
       "      <th>GIS_ACRES</th>\n",
       "      <th>Shape_Length</th>\n",
       "      <th>Shape_Area</th>\n",
       "      <th>index_right</th>\n",
       "      <th>fire_centroid</th>\n",
       "      <th>...</th>\n",
       "      <th>FIRE_AREA_KM2</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>year_month</th>\n",
       "      <th>end_year</th>\n",
       "      <th>end_month</th>\n",
       "      <th>duration_months</th>\n",
       "      <th>geometry</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NELSON</td>\n",
       "      <td>2020-06-18</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>11.0</td>\n",
       "      <td>109.602280</td>\n",
       "      <td>3252.523280</td>\n",
       "      <td>4.435447e+05</td>\n",
       "      <td>405.0</td>\n",
       "      <td>POINT (-121.3480590211847 38.88804091206984)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.443546</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>202006</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>POINT (-121.34806 38.88804)</td>\n",
       "      <td>38.888041</td>\n",
       "      <td>-121.348059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AMORUSO</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>2020-06-04</td>\n",
       "      <td>2.0</td>\n",
       "      <td>685.585022</td>\n",
       "      <td>9653.760308</td>\n",
       "      <td>2.774464e+06</td>\n",
       "      <td>1217.0</td>\n",
       "      <td>POINT (-121.3708983104108 38.82756661261951)</td>\n",
       "      <td>...</td>\n",
       "      <td>2.774464</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>202006</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>POINT (-121.37090 38.82757)</td>\n",
       "      <td>38.827567</td>\n",
       "      <td>-121.370898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>FLEMING</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.931545</td>\n",
       "      <td>1577.155857</td>\n",
       "      <td>5.233211e+04</td>\n",
       "      <td>405.0</td>\n",
       "      <td>POINT (-121.2734135751918 38.9623284462546)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052332</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>202003</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>POINT (-121.27341 38.96233)</td>\n",
       "      <td>38.962328</td>\n",
       "      <td>-121.273414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>MELANESE</td>\n",
       "      <td>2020-04-14</td>\n",
       "      <td>2020-04-19</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.315964</td>\n",
       "      <td>1035.787625</td>\n",
       "      <td>4.174722e+04</td>\n",
       "      <td>933.0</td>\n",
       "      <td>POINT (-121.3006534927401 39.48636412414794)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041747</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>202004</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>POINT (-121.30065 39.48636)</td>\n",
       "      <td>39.486364</td>\n",
       "      <td>-121.300653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>PFE</td>\n",
       "      <td>2020-07-05</td>\n",
       "      <td>2020-07-05</td>\n",
       "      <td>14.0</td>\n",
       "      <td>36.701931</td>\n",
       "      <td>2348.114043</td>\n",
       "      <td>1.485274e+05</td>\n",
       "      <td>1217.0</td>\n",
       "      <td>POINT (-121.3810176618852 38.73133921489409)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148527</td>\n",
       "      <td>2020</td>\n",
       "      <td>7</td>\n",
       "      <td>202007</td>\n",
       "      <td>2020</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>POINT (-121.38102 38.73134)</td>\n",
       "      <td>38.731339</td>\n",
       "      <td>-121.381018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9270</th>\n",
       "      <td>19698</td>\n",
       "      <td>TULLEY</td>\n",
       "      <td>2016-08-22</td>\n",
       "      <td>2016-09-04</td>\n",
       "      <td>7.0</td>\n",
       "      <td>607.445740</td>\n",
       "      <td>13095.080608</td>\n",
       "      <td>2.458246e+06</td>\n",
       "      <td>277.0</td>\n",
       "      <td>POINT (-123.8140318155857 41.28541623395056)</td>\n",
       "      <td>...</td>\n",
       "      <td>2.458246</td>\n",
       "      <td>2016</td>\n",
       "      <td>9</td>\n",
       "      <td>201609</td>\n",
       "      <td>2016</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>POINT (-123.81403 41.28542)</td>\n",
       "      <td>41.285416</td>\n",
       "      <td>-123.814032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9271</th>\n",
       "      <td>19720</td>\n",
       "      <td>DOCKERY</td>\n",
       "      <td>2016-07-30</td>\n",
       "      <td>2016-08-17</td>\n",
       "      <td>10.0</td>\n",
       "      <td>27.963249</td>\n",
       "      <td>2655.210701</td>\n",
       "      <td>1.131633e+05</td>\n",
       "      <td>51.0</td>\n",
       "      <td>POINT (-120.6873444598079 40.42539576204376)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113163</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>201608</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>POINT (-120.68734 40.42540)</td>\n",
       "      <td>40.425396</td>\n",
       "      <td>-120.687344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9272</th>\n",
       "      <td>19721</td>\n",
       "      <td>HOWARD</td>\n",
       "      <td>2016-09-11</td>\n",
       "      <td>2016-10-17</td>\n",
       "      <td>6.0</td>\n",
       "      <td>379.622528</td>\n",
       "      <td>7898.270122</td>\n",
       "      <td>1.536278e+06</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>POINT (-120.9157313359543 41.47071744410114)</td>\n",
       "      <td>...</td>\n",
       "      <td>1.536278</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>201610</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>POINT (-120.91573 41.47072)</td>\n",
       "      <td>41.470717</td>\n",
       "      <td>-120.915731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9273</th>\n",
       "      <td>19722</td>\n",
       "      <td>WILLARD</td>\n",
       "      <td>2016-09-11</td>\n",
       "      <td>2016-11-28</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2573.955322</td>\n",
       "      <td>27364.478495</td>\n",
       "      <td>1.041643e+07</td>\n",
       "      <td>51.0</td>\n",
       "      <td>POINT (-120.7510806570093 40.37593783404107)</td>\n",
       "      <td>...</td>\n",
       "      <td>10.416427</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>201610</td>\n",
       "      <td>2016</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>POINT (-120.75108 40.37594)</td>\n",
       "      <td>40.375938</td>\n",
       "      <td>-120.751081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9274</th>\n",
       "      <td>19722</td>\n",
       "      <td>WILLARD</td>\n",
       "      <td>2016-09-11</td>\n",
       "      <td>2016-11-28</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2573.955322</td>\n",
       "      <td>27364.478495</td>\n",
       "      <td>1.041643e+07</td>\n",
       "      <td>51.0</td>\n",
       "      <td>POINT (-120.7510806570093 40.37593783404107)</td>\n",
       "      <td>...</td>\n",
       "      <td>10.416427</td>\n",
       "      <td>2016</td>\n",
       "      <td>11</td>\n",
       "      <td>201611</td>\n",
       "      <td>2016</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>POINT (-120.75108 40.37594)</td>\n",
       "      <td>40.375938</td>\n",
       "      <td>-120.751081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9275 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fire_index FIRE_NAME  ALARM_DATE   CONT_DATE  CAUSE    GIS_ACRES  \\\n",
       "0              0    NELSON  2020-06-18  2020-06-23   11.0   109.602280   \n",
       "1              1   AMORUSO  2020-06-01  2020-06-04    2.0   685.585022   \n",
       "2              3   FLEMING  2020-03-31  2020-04-01    9.0    12.931545   \n",
       "3              4  MELANESE  2020-04-14  2020-04-19   18.0    10.315964   \n",
       "4              5       PFE  2020-07-05  2020-07-05   14.0    36.701931   \n",
       "...          ...       ...         ...         ...    ...          ...   \n",
       "9270       19698    TULLEY  2016-08-22  2016-09-04    7.0   607.445740   \n",
       "9271       19720   DOCKERY  2016-07-30  2016-08-17   10.0    27.963249   \n",
       "9272       19721    HOWARD  2016-09-11  2016-10-17    6.0   379.622528   \n",
       "9273       19722   WILLARD  2016-09-11  2016-11-28   14.0  2573.955322   \n",
       "9274       19722   WILLARD  2016-09-11  2016-11-28   14.0  2573.955322   \n",
       "\n",
       "      Shape_Length    Shape_Area  index_right  \\\n",
       "0      3252.523280  4.435447e+05        405.0   \n",
       "1      9653.760308  2.774464e+06       1217.0   \n",
       "2      1577.155857  5.233211e+04        405.0   \n",
       "3      1035.787625  4.174722e+04        933.0   \n",
       "4      2348.114043  1.485274e+05       1217.0   \n",
       "...            ...           ...          ...   \n",
       "9270  13095.080608  2.458246e+06        277.0   \n",
       "9271   2655.210701  1.131633e+05         51.0   \n",
       "9272   7898.270122  1.536278e+06       1021.0   \n",
       "9273  27364.478495  1.041643e+07         51.0   \n",
       "9274  27364.478495  1.041643e+07         51.0   \n",
       "\n",
       "                                     fire_centroid  ... FIRE_AREA_KM2  year  \\\n",
       "0     POINT (-121.3480590211847 38.88804091206984)  ...      0.443546  2020   \n",
       "1     POINT (-121.3708983104108 38.82756661261951)  ...      2.774464  2020   \n",
       "2      POINT (-121.2734135751918 38.9623284462546)  ...      0.052332  2020   \n",
       "3     POINT (-121.3006534927401 39.48636412414794)  ...      0.041747  2020   \n",
       "4     POINT (-121.3810176618852 38.73133921489409)  ...      0.148527  2020   \n",
       "...                                            ...  ...           ...   ...   \n",
       "9270  POINT (-123.8140318155857 41.28541623395056)  ...      2.458246  2016   \n",
       "9271  POINT (-120.6873444598079 40.42539576204376)  ...      0.113163  2016   \n",
       "9272  POINT (-120.9157313359543 41.47071744410114)  ...      1.536278  2016   \n",
       "9273  POINT (-120.7510806570093 40.37593783404107)  ...     10.416427  2016   \n",
       "9274  POINT (-120.7510806570093 40.37593783404107)  ...     10.416427  2016   \n",
       "\n",
       "      month  year_month  end_year  end_month  duration_months  \\\n",
       "0         6      202006      2020          6                1   \n",
       "1         6      202006      2020          6                1   \n",
       "2         3      202003      2020          4                2   \n",
       "3         4      202004      2020          4                1   \n",
       "4         7      202007      2020          7                1   \n",
       "...     ...         ...       ...        ...              ...   \n",
       "9270      9      201609      2016          9                1   \n",
       "9271      8      201608      2016          8                1   \n",
       "9272     10      201610      2016         10                1   \n",
       "9273     10      201610      2016         11                2   \n",
       "9274     11      201611      2016         11                1   \n",
       "\n",
       "                         geometry        lat         lon  \n",
       "0     POINT (-121.34806 38.88804)  38.888041 -121.348059  \n",
       "1     POINT (-121.37090 38.82757)  38.827567 -121.370898  \n",
       "2     POINT (-121.27341 38.96233)  38.962328 -121.273414  \n",
       "3     POINT (-121.30065 39.48636)  39.486364 -121.300653  \n",
       "4     POINT (-121.38102 38.73134)  38.731339 -121.381018  \n",
       "...                           ...        ...         ...  \n",
       "9270  POINT (-123.81403 41.28542)  41.285416 -123.814032  \n",
       "9271  POINT (-120.68734 40.42540)  40.425396 -120.687344  \n",
       "9272  POINT (-120.91573 41.47072)  41.470717 -120.915731  \n",
       "9273  POINT (-120.75108 40.37594)  40.375938 -120.751081  \n",
       "9274  POINT (-120.75108 40.37594)  40.375938 -120.751081  \n",
       "\n",
       "[9275 rows x 21 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire_fix = pd.read_csv('../data/interim/fires_all_months.csv',index_col=0)\n",
    "fire_fix[\"geometry\"] = gpd.GeoSeries.from_wkt(fire_fix[\"fire_centroid\"])\n",
    "fire_fix['lat']=fire_fix['geometry'].apply(lambda temp: temp.y)\n",
    "fire_fix['lon']=fire_fix['geometry'].apply(lambda temp: temp.x)\n",
    "fire_fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_clean_wind(year):\n",
    "    \"\"\"\n",
    "    Read in wind data by year\n",
    "    \"\"\"\n",
    "    # create empty df\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for file in os.listdir(in_dir_wind):\n",
    "        if file.startswith('MERRA2') and file[-10:-6] == str(year):\n",
    "\n",
    "            ## read .nc file ##\n",
    "            ###################\n",
    "            data = ncdf.Dataset(\n",
    "                in_dir_wind + file, mode='r'\n",
    "            )\n",
    "            # print metadata\n",
    "            #print(data)\n",
    "\n",
    "            # grab vars of interest ##\n",
    "            ##########################\n",
    "            # longitude and latitude\n",
    "            lons = data.variables['lon']\n",
    "            lats = data.variables['lat']\n",
    "            # 2-meter eastward wind m/s\n",
    "            U2M = data.variables['U2M']\n",
    "            # 2-meter northward wind m/s\n",
    "            V2M = data.variables['V2M']\n",
    "\n",
    "            # Replace vals #\n",
    "            ################\n",
    "            #\\_FillValues with NaNs:\n",
    "            U2M_nans = U2M[:]\n",
    "            V2M_nans = V2M[:]\n",
    "            _FillValueU2M = U2M._FillValue\n",
    "            _FillValueV2M = V2M._FillValue\n",
    "            U2M_nans[U2M_nans == _FillValueU2M] = np.nan\n",
    "            V2M_nans[V2M_nans == _FillValueV2M] = np.nan\n",
    "\n",
    "            # Add new vars #\n",
    "            ################\n",
    "            # calculate wind speed\n",
    "            wspd = np.sqrt(U2M_nans**2+V2M_nans**2)\n",
    "\n",
    "            # calculate wind direction in radians\n",
    "            wdir = np.arctan2(V2M_nans, U2M_nans)\n",
    "            #WDIR= (270-atan2(V,U)*180/pi)%360\n",
    "            \n",
    "            # transform wind direction from radians to degrees\n",
    "            #dir_to_degrees = np.mod(180+np.rad2deg(np.arctan2(V2M_nans, U2M_nans)), 360) # this computes \"wind is blowing from\"' meteorological convetion'\n",
    "            wdir_to_degrees = np.mod(np.rad2deg(wdir), 360) # this computes \"wind is blowing towards\" 'oceonographic convention', see here: https://www.esri.com/arcgis-blog/products/product/analytics/displaying-speed-and-direction-symbology-from-u-and-v-vectors/\n",
    "            \n",
    "            \n",
    "            ## transform to df ##\n",
    "            #####################\n",
    "            # create an empty df for wind speed and direction with size len(lats) x len(lons) \n",
    "            df_wdir = pd.DataFrame(index=lats[:], columns=lons[:])   \n",
    "            df_wspd = pd.DataFrame(index=lats[:], columns=lons[:])\n",
    "            \n",
    "            # create an empty df for u and v components with size len(lats) x len(lons) \n",
    "            df_u = pd.DataFrame(index=lats[:], columns=lons[:])\n",
    "            df_v = pd.DataFrame(index=lats[:], columns=lons[:])\n",
    "\n",
    "            # populate each row in the empty df above with the wdir_meteo and wspd data and u and v components\n",
    "            for idx, idx_val in enumerate(df_wdir.index):\n",
    "                df_wdir.loc[idx_val, :] = wdir_to_degrees[0][idx]\n",
    "                df_wspd.loc[idx_val, :] = wspd[0][idx]\n",
    "                df_u.loc[idx_val, :] = U2M_nans[0][idx]\n",
    "                df_v.loc[idx_val, :] = V2M_nans[0][idx]\n",
    "\n",
    "            # add index (latitude) as column\n",
    "            df_wdir.reset_index(\n",
    "                drop=False,\n",
    "                inplace=True\n",
    "            )\n",
    "            \n",
    "            df_wdir.rename(\n",
    "                columns={'index':'lat'},\n",
    "                inplace=True\n",
    "            )\n",
    "            \n",
    "            \n",
    "            df_wspd.reset_index(\n",
    "                drop=False,\n",
    "                inplace=True\n",
    "            )\n",
    "            \n",
    "            df_wspd.rename(\n",
    "                columns={'index':'lat'},\n",
    "                inplace=True\n",
    "            )\n",
    "            \n",
    "            df_u.reset_index(\n",
    "                drop=False,\n",
    "                inplace=True\n",
    "            )\n",
    "            \n",
    "            df_u.rename(\n",
    "                columns={'index':'lat'},\n",
    "                inplace=True\n",
    "            )\n",
    "            \n",
    "            df_v.reset_index(\n",
    "                drop=False,\n",
    "                inplace=True\n",
    "            )\n",
    "            \n",
    "            df_v.rename(\n",
    "                columns={'index':'lat'},\n",
    "                inplace=True\n",
    "            )\n",
    "\n",
    "            # transform from wide to long\n",
    "            df_wdir = pd.melt(\n",
    "                df_wdir, id_vars='lat',\n",
    "                var_name='lon',\n",
    "                value_vars=lons[:],\n",
    "                value_name='wdir'\n",
    "            )\n",
    "            \n",
    "            df_wspd = pd.melt(\n",
    "                df_wspd,\n",
    "                id_vars='lat',\n",
    "                var_name='lon',\n",
    "                value_vars=lons[:],\n",
    "                value_name='wspd'\n",
    "            )\n",
    "            \n",
    "            df_u = pd.melt(\n",
    "                df_u, id_vars='lat',\n",
    "                var_name='lon',\n",
    "                value_vars=lons[:],\n",
    "                value_name='u'\n",
    "            )\n",
    "            \n",
    "            df_v = pd.melt(\n",
    "                df_v, id_vars='lat',\n",
    "                var_name='lon',\n",
    "                value_vars=lons[:],\n",
    "                value_name='v'\n",
    "            )\n",
    "\n",
    "            # concatenate df_wdir and df_wspd\n",
    "            df_temp1 = df_wdir.merge(\n",
    "                df_wspd,\n",
    "                on=['lat', 'lon'],\n",
    "                how='left'\n",
    "            )\n",
    "            \n",
    "            # concatenate df_u and df_v\n",
    "            df_temp2 = df_u.merge(\n",
    "                df_v,\n",
    "                on=['lat', 'lon'],\n",
    "                how='left'\n",
    "            )\n",
    "            \n",
    "            # concatenate df_temp1 and df_temp2\n",
    "            df_temp = df_temp2.merge(\n",
    "                df_temp1,\n",
    "                on=['lat', 'lon'],\n",
    "                how='left'\n",
    "            )\n",
    "            \n",
    "            # add time stamp \n",
    "            df_temp['year_month'] = file.split('.')[2]\n",
    "\n",
    "            df = pd.concat(\n",
    "                [df_temp, df],\n",
    "                axis=0\n",
    "            )\n",
    "   \n",
    "    # keep values in min, max range of California geometry\n",
    "    df = df[\n",
    "        df.lon.ge(-125) & df.lon.le(-115) & df.lat.ge(32) & df.lat.le(42)\n",
    "    ]\n",
    "    \n",
    "    # transform vars\n",
    "    df['lat'] = df.lat.astype(float)\n",
    "    df['lon'] = df.lon.astype(float)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``read census geom``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_census_geom():\n",
    "    \"\"\" Read Census (lat, lon) coordinates for California zip-codes\n",
    "    parameters:\n",
    "    -----------\n",
    "    None\n",
    "    \n",
    "    return:\n",
    "    -------\n",
    "    Df with osmnx_geom\n",
    "    \"\"\"\n",
    "    ### Step 1 ### \n",
    "    ##############\n",
    "    # Read the shapefiles for California's ZIP codes\n",
    "    for file in os.listdir(in_dir_zip_shapes):\n",
    "        if file.endswith('.shp'):\n",
    "            gdf = gpd.read_file(in_dir_zip_shapes + file)\n",
    "\n",
    "    # keep only cols of interest \n",
    "    # ('ZCTA5CE10' = 2010 Census ZIP codes,\t'GEOID10' = 2010 Census Tract codes)\n",
    "    gdf = gdf[\n",
    "        ['ZCTA5CE10',\n",
    "         'GEOID10',\n",
    "         'geometry']\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    ### Step 2 ###\n",
    "    ###############\n",
    "    # For each zip cpde extract polygon with (lat, lon) info\n",
    "\n",
    "    zip_poly = pd.DataFrame()\n",
    "\n",
    "    for idx, multipoly in enumerate(gdf.geometry):\n",
    "        if isinstance(multipoly, shapely.geometry.polygon.Polygon):\n",
    "            temp_df = pd.DataFrame(\n",
    "                {\n",
    "                    'lat': multipoly.exterior.coords.xy[1], \n",
    "                    'lon': multipoly.exterior.coords.xy[0],\n",
    "                    'ZCTA10': gdf.loc[idx, 'ZCTA5CE10'],\n",
    "                    'GEOID10': gdf.loc[idx, 'GEOID10']\n",
    "                }\n",
    "            )\n",
    "            zip_poly = pd.concat(\n",
    "                [zip_poly, temp_df],\n",
    "                axis=0\n",
    "            )\n",
    "\n",
    "        if isinstance(multipoly, shapely.geometry.multipolygon.MultiPolygon):\n",
    "            for poly in multipoly:\n",
    "                temp_df = pd.DataFrame(\n",
    "                    {\n",
    "                        'lat': poly.exterior.coords.xy[1], \n",
    "                        'lon': poly.exterior.coords.xy[0],\n",
    "                        'ZCTA10': gdf.loc[idx, 'ZCTA5CE10'],\n",
    "                        'GEOID10': gdf.loc[idx, 'GEOID10']\n",
    "                    }\n",
    "                )\n",
    "                zip_poly = pd.concat(\n",
    "                    [zip_poly, temp_df],\n",
    "                    axis=0\n",
    "                )   \n",
    "    \n",
    "\n",
    "    # round (lat, lon) to 2 decimal points and add 0.005 to match the UW (lat, lon) values\n",
    "    zip_poly['lat'] = zip_poly.lat.round(3)\n",
    "    zip_poly['lon'] = zip_poly.lon.round(3)\n",
    "    \n",
    "    zip_poly.sort_values(\n",
    "        by=['ZCTA10', 'lat', 'lon'],\n",
    "        inplace=True\n",
    "    )\n",
    "    \n",
    "    zip_poly.drop_duplicates(\n",
    "        subset=['ZCTA10', 'lat', 'lon'],\n",
    "        inplace=True\n",
    "    )\n",
    "\n",
    "    zip_poly.reset_index(\n",
    "        drop=True,\n",
    "        inplace=True\n",
    "    )\n",
    "    \n",
    "    return zip_poly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``find zip (zcta) code for wind data``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_wind_to_fire(df1, df2):\n",
    "    '''\n",
    "    params:\n",
    "    -------\n",
    "    df1: wind data\n",
    "    df2: fire geometry data\n",
    "    \n",
    "    return:\n",
    "    -------\n",
    "    '''\n",
    "    \n",
    "    # create labels\n",
    "    df1['wind_lat_lon'] = [str(xy) for xy in zip(df1.lat, df1.lon)]\n",
    "    df2['fire_lat_lon'] = [str(xy) for xy in zip(df2.lat, df2.lon)]\n",
    "\n",
    "    ## for each point in wind data find the nearest point in the census data ##\n",
    "    ###############\n",
    "    # keep only unique points in wind data\n",
    "    df1_unique = df1.drop_duplicates(\n",
    "        ['wind_lat_lon']\n",
    "    )\n",
    "    \n",
    "    df2_unique = df2.drop_duplicates(\n",
    "        ['fire_lat_lon']\n",
    "    )\n",
    "    \n",
    "    df1_unique.reset_index(\n",
    "        drop=True,\n",
    "        inplace=True\n",
    "    )\n",
    "    \n",
    "    df2_unique.reset_index(\n",
    "        drop=True,\n",
    "        inplace=True\n",
    "    )\n",
    "\n",
    "    # transform to radians\n",
    "    df1_unique['lat_r'] = np.radians(df1_unique.lat)\n",
    "    df1_unique['lon_r'] = np.radians(df1_unique.lon)\n",
    "    df2_unique['lat_r'] = np.radians(df2_unique.lat)\n",
    "    df2_unique['lon_r'] = np.radians(df2_unique.lon)\n",
    "\n",
    "\n",
    "    # compute pairwise distance (in miles)\n",
    "    dist_matrix = (dist.pairwise(\n",
    "        df2_unique[['lat_r', 'lon_r']],\n",
    "        df1_unique[['lat_r', 'lon_r']]\n",
    "    ))*3959\n",
    "\n",
    "    # create a df from dist_matrix\n",
    "    dist_matrix = pd.DataFrame(\n",
    "        dist_matrix,\n",
    "        index=df2_unique['fire_lat_lon'],\n",
    "        columns=df1_unique['wind_lat_lon']\n",
    "    )\n",
    "    \n",
    "    # for each row (fire_lat_lon point) extract the closest column (wind_lat_lon point) \n",
    "    closest_point = pd.DataFrame(\n",
    "        dist_matrix.idxmin(axis=1),\n",
    "        columns=['closest_wind_lat_lon']\n",
    "    )\n",
    "    \n",
    "    closest_point.reset_index(\n",
    "        drop=False,\n",
    "        inplace=True\n",
    "    )\n",
    "\n",
    "    # merge with fire data\n",
    "    df2_unique = df2.merge(\n",
    "        closest_point,\n",
    "        on='fire_lat_lon',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # merge with fire data \n",
    "    df2_unique = df2_unique.merge(\n",
    "        df2[['fire_lat_lon']],\n",
    "        on=['fire_lat_lon'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # # replicate df2_unique based on number of year_month entries in df1\n",
    "    # df2_unique = pd.concat(\n",
    "    #     [df2_unique]*(df1.year_month.nunique()),\n",
    "    #     axis=0\n",
    "    # )\n",
    "    \n",
    "#     df2_unique.reset_index(\n",
    "#         drop=True,\n",
    "#         inplace=True\n",
    "#     )\n",
    "\n",
    "#     # add year_month column to df2_unique\n",
    "#     df2_unique['year_month'] = 0\n",
    "#     indeces = [n for n in range(1, df2_unique.shape[0]) if n%(df2_unique.shape[0]-1)==0]\n",
    "    \n",
    "#     year_month = np.sort(df1.year_month.unique())\n",
    "#     print(indeces)\n",
    "#     for idx, index in enumerate(indeces):\n",
    "#         if idx==0:\n",
    "#             df2_unique.iloc[0:indeces[idx], 17] = year_month[idx]\n",
    "#         else:\n",
    "#             df2_unique.iloc[indeces[idx-1]:indeces[idx], 17] = year_month[idx]\n",
    "    \n",
    "    df2['year_month'] = df2['year_month'].astype(int)\n",
    "    df1['year_month'] = df1['year_month'].astype(int)\n",
    "    \n",
    "    # from df1 keep only cols of interest\n",
    "    df1 = df1[\n",
    "        ['year_month',\n",
    "         'u',\n",
    "         'v',\n",
    "         'wdir',\n",
    "         'wspd',\n",
    "         'wind_lat_lon']\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    # merge df2_unique with df1\n",
    "    df2_unique = df2_unique.merge(\n",
    "        df1,\n",
    "        left_on=['year_month', 'closest_wind_lat_lon'],\n",
    "        right_on=['year_month', 'wind_lat_lon'],\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # keep only cols of interest\n",
    "    df2_unique = df2_unique[\n",
    "        ['lat',\n",
    "         'lon',\n",
    "         'fire_lat_lon','wind_lat_lon',\n",
    "         'fire_index','ALARM_DATE','CONT_DATE','fire_centroid','geometry','GIS_ACRES',\n",
    "         'u',\n",
    "         'v',\n",
    "         'wdir',\n",
    "         'wspd',\n",
    "         'year_month']\n",
    "    ]\n",
    "    \n",
    "    df2_unique.dropna(\n",
    "        inplace=True\n",
    "    )\n",
    "    \n",
    "    df2_unique.reset_index(\n",
    "        drop=True,\n",
    "        inplace=True\n",
    "    )\n",
    "    \n",
    "    df2_unique.drop_duplicates(\n",
    "    ['year_month', 'fire_lat_lon'],\n",
    "    inplace=True\n",
    "    )\n",
    "\n",
    "    df2_unique.reset_index(\n",
    "        drop=True,\n",
    "        inplace=True\n",
    "    )\n",
    "    \n",
    "    return df2_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fire_index', 'FIRE_NAME', 'ALARM_DATE', 'CONT_DATE', 'CAUSE',\n",
       "       'GIS_ACRES', 'Shape_Length', 'Shape_Area', 'index_right',\n",
       "       'fire_centroid', 'DURATION', 'FIRE_AREA_KM2', 'year', 'month',\n",
       "       'year_month', 'end_year', 'end_month', 'duration_months', 'geometry',\n",
       "       'lat', 'lon'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire_fix.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>fire_lat_lon</th>\n",
       "      <th>wind_lat_lon</th>\n",
       "      <th>fire_index</th>\n",
       "      <th>ALARM_DATE</th>\n",
       "      <th>CONT_DATE</th>\n",
       "      <th>fire_centroid</th>\n",
       "      <th>geometry</th>\n",
       "      <th>GIS_ACRES</th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>wdir</th>\n",
       "      <th>wspd</th>\n",
       "      <th>year_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35.398070</td>\n",
       "      <td>-118.460928</td>\n",
       "      <td>(35.3980703184682, -118.4609278999623)</td>\n",
       "      <td>(35.5, -118.75)</td>\n",
       "      <td>13113</td>\n",
       "      <td>2012-06-07</td>\n",
       "      <td>2012-06-07</td>\n",
       "      <td>POINT (-118.4609278999623 35.3980703184682)</td>\n",
       "      <td>POINT (-118.46093 35.39807)</td>\n",
       "      <td>0.781771</td>\n",
       "      <td>1.561013</td>\n",
       "      <td>-0.93303</td>\n",
       "      <td>329.132904</td>\n",
       "      <td>1.818601</td>\n",
       "      <td>201206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34.953104</td>\n",
       "      <td>-118.898129</td>\n",
       "      <td>(34.95310420967192, -118.8981290564402)</td>\n",
       "      <td>(35.0, -118.75)</td>\n",
       "      <td>13114</td>\n",
       "      <td>2012-06-22</td>\n",
       "      <td>2012-06-22</td>\n",
       "      <td>POINT (-118.8981290564402 34.95310420967192)</td>\n",
       "      <td>POINT (-118.89813 34.95310)</td>\n",
       "      <td>13.108104</td>\n",
       "      <td>1.252996</td>\n",
       "      <td>-1.590386</td>\n",
       "      <td>308.233063</td>\n",
       "      <td>2.024679</td>\n",
       "      <td>201206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.906430</td>\n",
       "      <td>-119.209412</td>\n",
       "      <td>(34.90642952082512, -119.2094120604393)</td>\n",
       "      <td>(35.0, -119.375)</td>\n",
       "      <td>13115</td>\n",
       "      <td>2012-06-29</td>\n",
       "      <td>2012-06-29</td>\n",
       "      <td>POINT (-119.2094120604393 34.90642952082512)</td>\n",
       "      <td>POINT (-119.20941 34.90643)</td>\n",
       "      <td>173.271912</td>\n",
       "      <td>0.908553</td>\n",
       "      <td>-1.504646</td>\n",
       "      <td>301.124908</td>\n",
       "      <td>1.757677</td>\n",
       "      <td>201206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.908043</td>\n",
       "      <td>-118.893601</td>\n",
       "      <td>(34.90804254980864, -118.8936006460696)</td>\n",
       "      <td>(35.0, -118.75)</td>\n",
       "      <td>13116</td>\n",
       "      <td>2012-06-18</td>\n",
       "      <td>2012-06-18</td>\n",
       "      <td>POINT (-118.8936006460696 34.90804254980864)</td>\n",
       "      <td>POINT (-118.89360 34.90804)</td>\n",
       "      <td>206.098831</td>\n",
       "      <td>1.252996</td>\n",
       "      <td>-1.590386</td>\n",
       "      <td>308.233063</td>\n",
       "      <td>2.024679</td>\n",
       "      <td>201206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.123759</td>\n",
       "      <td>-119.459332</td>\n",
       "      <td>(35.12375866296951, -119.4593318706585)</td>\n",
       "      <td>(35.0, -119.375)</td>\n",
       "      <td>13117</td>\n",
       "      <td>2012-06-21</td>\n",
       "      <td>2012-06-21</td>\n",
       "      <td>POINT (-119.4593318706585 35.12375866296951)</td>\n",
       "      <td>POINT (-119.45933 35.12376)</td>\n",
       "      <td>14.685063</td>\n",
       "      <td>0.908553</td>\n",
       "      <td>-1.504646</td>\n",
       "      <td>301.124908</td>\n",
       "      <td>1.757677</td>\n",
       "      <td>201206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>37.775985</td>\n",
       "      <td>-119.674782</td>\n",
       "      <td>(37.7759853399845, -119.6747818056264)</td>\n",
       "      <td>(38.0, -119.375)</td>\n",
       "      <td>19088</td>\n",
       "      <td>2012-06-16</td>\n",
       "      <td>2012-11-09</td>\n",
       "      <td>POINT (-119.6747818056264 37.7759853399845)</td>\n",
       "      <td>POINT (-119.67478 37.77599)</td>\n",
       "      <td>1704.925903</td>\n",
       "      <td>0.711625</td>\n",
       "      <td>0.779979</td>\n",
       "      <td>47.623787</td>\n",
       "      <td>1.055831</td>\n",
       "      <td>201207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>37.775985</td>\n",
       "      <td>-119.674782</td>\n",
       "      <td>(37.7759853399845, -119.6747818056264)</td>\n",
       "      <td>(38.0, -119.375)</td>\n",
       "      <td>19088</td>\n",
       "      <td>2012-06-16</td>\n",
       "      <td>2012-11-09</td>\n",
       "      <td>POINT (-119.6747818056264 37.7759853399845)</td>\n",
       "      <td>POINT (-119.67478 37.77599)</td>\n",
       "      <td>1704.925903</td>\n",
       "      <td>0.487091</td>\n",
       "      <td>0.435951</td>\n",
       "      <td>41.82885</td>\n",
       "      <td>0.65369</td>\n",
       "      <td>201208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>37.775985</td>\n",
       "      <td>-119.674782</td>\n",
       "      <td>(37.7759853399845, -119.6747818056264)</td>\n",
       "      <td>(38.0, -119.375)</td>\n",
       "      <td>19088</td>\n",
       "      <td>2012-06-16</td>\n",
       "      <td>2012-11-09</td>\n",
       "      <td>POINT (-119.6747818056264 37.7759853399845)</td>\n",
       "      <td>POINT (-119.67478 37.77599)</td>\n",
       "      <td>1704.925903</td>\n",
       "      <td>0.213126</td>\n",
       "      <td>0.362542</td>\n",
       "      <td>59.550182</td>\n",
       "      <td>0.420546</td>\n",
       "      <td>201209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>37.775985</td>\n",
       "      <td>-119.674782</td>\n",
       "      <td>(37.7759853399845, -119.6747818056264)</td>\n",
       "      <td>(38.0, -119.375)</td>\n",
       "      <td>19088</td>\n",
       "      <td>2012-06-16</td>\n",
       "      <td>2012-11-09</td>\n",
       "      <td>POINT (-119.6747818056264 37.7759853399845)</td>\n",
       "      <td>POINT (-119.67478 37.77599)</td>\n",
       "      <td>1704.925903</td>\n",
       "      <td>0.435755</td>\n",
       "      <td>0.338613</td>\n",
       "      <td>37.849804</td>\n",
       "      <td>0.551853</td>\n",
       "      <td>201210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>37.775985</td>\n",
       "      <td>-119.674782</td>\n",
       "      <td>(37.7759853399845, -119.6747818056264)</td>\n",
       "      <td>(38.0, -119.375)</td>\n",
       "      <td>19088</td>\n",
       "      <td>2012-06-16</td>\n",
       "      <td>2012-11-09</td>\n",
       "      <td>POINT (-119.6747818056264 37.7759853399845)</td>\n",
       "      <td>POINT (-119.67478 37.77599)</td>\n",
       "      <td>1704.925903</td>\n",
       "      <td>0.607435</td>\n",
       "      <td>0.929866</td>\n",
       "      <td>56.845398</td>\n",
       "      <td>1.110688</td>\n",
       "      <td>201211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           lat         lon                             fire_lat_lon  \\\n",
       "0    35.398070 -118.460928   (35.3980703184682, -118.4609278999623)   \n",
       "1    34.953104 -118.898129  (34.95310420967192, -118.8981290564402)   \n",
       "2    34.906430 -119.209412  (34.90642952082512, -119.2094120604393)   \n",
       "3    34.908043 -118.893601  (34.90804254980864, -118.8936006460696)   \n",
       "4    35.123759 -119.459332  (35.12375866296951, -119.4593318706585)   \n",
       "..         ...         ...                                      ...   \n",
       "395  37.775985 -119.674782   (37.7759853399845, -119.6747818056264)   \n",
       "396  37.775985 -119.674782   (37.7759853399845, -119.6747818056264)   \n",
       "397  37.775985 -119.674782   (37.7759853399845, -119.6747818056264)   \n",
       "398  37.775985 -119.674782   (37.7759853399845, -119.6747818056264)   \n",
       "399  37.775985 -119.674782   (37.7759853399845, -119.6747818056264)   \n",
       "\n",
       "         wind_lat_lon  fire_index  ALARM_DATE   CONT_DATE  \\\n",
       "0     (35.5, -118.75)       13113  2012-06-07  2012-06-07   \n",
       "1     (35.0, -118.75)       13114  2012-06-22  2012-06-22   \n",
       "2    (35.0, -119.375)       13115  2012-06-29  2012-06-29   \n",
       "3     (35.0, -118.75)       13116  2012-06-18  2012-06-18   \n",
       "4    (35.0, -119.375)       13117  2012-06-21  2012-06-21   \n",
       "..                ...         ...         ...         ...   \n",
       "395  (38.0, -119.375)       19088  2012-06-16  2012-11-09   \n",
       "396  (38.0, -119.375)       19088  2012-06-16  2012-11-09   \n",
       "397  (38.0, -119.375)       19088  2012-06-16  2012-11-09   \n",
       "398  (38.0, -119.375)       19088  2012-06-16  2012-11-09   \n",
       "399  (38.0, -119.375)       19088  2012-06-16  2012-11-09   \n",
       "\n",
       "                                    fire_centroid  \\\n",
       "0     POINT (-118.4609278999623 35.3980703184682)   \n",
       "1    POINT (-118.8981290564402 34.95310420967192)   \n",
       "2    POINT (-119.2094120604393 34.90642952082512)   \n",
       "3    POINT (-118.8936006460696 34.90804254980864)   \n",
       "4    POINT (-119.4593318706585 35.12375866296951)   \n",
       "..                                            ...   \n",
       "395   POINT (-119.6747818056264 37.7759853399845)   \n",
       "396   POINT (-119.6747818056264 37.7759853399845)   \n",
       "397   POINT (-119.6747818056264 37.7759853399845)   \n",
       "398   POINT (-119.6747818056264 37.7759853399845)   \n",
       "399   POINT (-119.6747818056264 37.7759853399845)   \n",
       "\n",
       "                        geometry    GIS_ACRES         u         v        wdir  \\\n",
       "0    POINT (-118.46093 35.39807)     0.781771  1.561013  -0.93303  329.132904   \n",
       "1    POINT (-118.89813 34.95310)    13.108104  1.252996 -1.590386  308.233063   \n",
       "2    POINT (-119.20941 34.90643)   173.271912  0.908553 -1.504646  301.124908   \n",
       "3    POINT (-118.89360 34.90804)   206.098831  1.252996 -1.590386  308.233063   \n",
       "4    POINT (-119.45933 35.12376)    14.685063  0.908553 -1.504646  301.124908   \n",
       "..                           ...          ...       ...       ...         ...   \n",
       "395  POINT (-119.67478 37.77599)  1704.925903  0.711625  0.779979   47.623787   \n",
       "396  POINT (-119.67478 37.77599)  1704.925903  0.487091  0.435951    41.82885   \n",
       "397  POINT (-119.67478 37.77599)  1704.925903  0.213126  0.362542   59.550182   \n",
       "398  POINT (-119.67478 37.77599)  1704.925903  0.435755  0.338613   37.849804   \n",
       "399  POINT (-119.67478 37.77599)  1704.925903  0.607435  0.929866   56.845398   \n",
       "\n",
       "         wspd  year_month  \n",
       "0    1.818601      201206  \n",
       "1    2.024679      201206  \n",
       "2    1.757677      201206  \n",
       "3    2.024679      201206  \n",
       "4    1.757677      201206  \n",
       "..        ...         ...  \n",
       "395  1.055831      201207  \n",
       "396   0.65369      201208  \n",
       "397  0.420546      201209  \n",
       "398  0.551853      201210  \n",
       "399  1.110688      201211  \n",
       "\n",
       "[400 rows x 15 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test the join\n",
    "\n",
    "df = read_clean_wind(2012)\n",
    "df_final = add_wind_to_fire(df, fire_fix)\n",
    "df_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- File 1991_fire_winds.csv already exists. -\n",
      "- File 1992_fire_winds.csv already exists. -\n",
      "- File 1993_fire_winds.csv already exists. -\n",
      "- File 1994_fire_winds.csv already exists. -\n",
      "- File 1995_fire_winds.csv already exists. -\n",
      "- File 1996_fire_winds.csv already exists. -\n",
      "- File 1997_fire_winds.csv already exists. -\n",
      "- File 1998_fire_winds.csv already exists. -\n",
      "- File 1999_fire_winds.csv already exists. -\n",
      "- File 2000_fire_winds.csv already exists. -\n",
      "- File 2001_fire_winds.csv already exists. -\n",
      "- File 2002_fire_winds.csv already exists. -\n",
      "- File 2003_fire_winds.csv already exists. -\n",
      "- File 2004_fire_winds.csv already exists. -\n",
      "- File 2005_fire_winds.csv already exists. -\n",
      "- File 2006_fire_winds.csv already exists. -\n",
      "- File 2007_fire_winds.csv already exists. -\n",
      "- File 2008_fire_winds.csv already exists. -\n",
      "- File 2009_fire_winds.csv already exists. -\n",
      "- File 2010_fire_winds.csv already exists. -\n",
      "- File 2011_fire_winds.csv already exists. -\n",
      "- File 2012_fire_winds.csv already exists. -\n",
      "- File 2013_fire_winds.csv already exists. -\n",
      "- File 2014_fire_winds.csv already exists. -\n",
      "- File 2015_fire_winds.csv already exists. -\n",
      "- File 2016_fire_winds.csv already exists. -\n",
      "- File 2017_fire_winds.csv already exists. -\n",
      "- File 2018_fire_winds.csv already exists. -\n",
      "- File 2019_fire_winds.csv already exists. -\n",
      "- File 2020_fire_winds.csv already exists. -\n",
      "- File 2021_fire_winds.csv already exists. -\n",
      "- File 2022_fire_winds.csv already exists. -\n"
     ]
    }
   ],
   "source": [
    "for year in range(1991,2023):\n",
    "    if os.path.exists(out_dir + str(year) + '_fire_winds.csv'):\n",
    "        print('- File ' + str(year) + '_fire_winds.csv already exists. -')\n",
    "    else:\n",
    "        print(f'----- Starting on year {year} -----')\n",
    "        df = read_clean_wind(year)\n",
    "        df_final = add_wind_to_fire(df, fire_fix)\n",
    "        df_final.to_csv(out_dir  + str(year) + '_fire_winds.csv')\n",
    "        print('--- Now saving file ' + out_dir  + str(year) + '_fire_winds.csv ---')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``census geom``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/processed/1993_fire_winds.csv\n",
      "../data/processed/all_year_fire_wind.csv\n",
      "../data/processed/1994_fire_winds.csv\n",
      "../data/processed/2021_fire_winds.csv\n",
      "../data/processed/1995_fire_winds.csv\n",
      "../data/processed/2020_fire_winds.csv\n",
      "../data/processed/1992_fire_winds.csv\n",
      "../data/processed/1998_fire_winds.csv\n",
      "../data/processed/2022_fire_winds.csv\n",
      "../data/processed/1997_fire_winds.csv\n",
      "../data/processed/1996_fire_winds.csv\n",
      "../data/processed/1999_fire_winds.csv\n",
      "../data/processed/1991_fire_winds.csv\n",
      "../data/processed/2018_fire_winds.csv\n",
      "../data/processed/2010_fire_winds.csv\n",
      "../data/processed/2005_fire_winds.csv\n",
      "../data/processed/2002_fire_winds.csv\n",
      "../data/processed/2017_fire_winds.csv\n",
      "../data/processed/2016_fire_winds.csv\n",
      "../data/processed/2003_fire_winds.csv\n",
      "../data/processed/2004_fire_winds.csv\n",
      "../data/processed/2011_fire_winds.csv\n",
      "../data/processed/2019_fire_winds.csv\n",
      "../data/processed/2006_fire_winds.csv\n",
      "../data/processed/2013_fire_winds.csv\n",
      "../data/processed/2014_fire_winds.csv\n",
      "../data/processed/2001_fire_winds.csv\n",
      "../data/processed/2009_fire_winds.csv\n",
      "../data/processed/2008_fire_winds.csv\n",
      "../data/processed/2000_fire_winds.csv\n",
      "../data/processed/2015_fire_winds.csv\n",
      "../data/processed/2012_fire_winds.csv\n",
      "../data/processed/2007_fire_winds.csv\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "files = glob.glob(out_dir+'*.csv')\n",
    "df_all_years = pd.DataFrame()\n",
    "\n",
    "for f in files:\n",
    "    print(f)\n",
    "    if (f != '../data/processed/all_year_fire_wind.csv' \n",
    "        and f != 'fire_wind_processed.csv'):\n",
    "        csv = pd.read_csv(f)\n",
    "    df_all_years = df_all_years.append(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_all_years = pd.read_csv(out_dir + 'all_year_fire_wind.csv',index_col=0)\n",
    "df_all_years['year_month']=df_all_years['year_month'].astype(str)\n",
    "df_all_years['year']=df_all_years['year_month'].str.slice(start=0,stop=4)\n",
    "df_all_years['month']=df_all_years['year_month'].str.slice(start=4,stop=6)\n",
    "df_all_years = df_all_years.drop(['lon','fire_index','lat','wind_lat_lon','geometry','u','v','Unnamed: 0'],axis=1).reset_index(drop=True)\n",
    "df_all_years = df_all_years.rename(columns={'wdir':'fire_wdir',\n",
    "                             'wspd':'fire_wspd'})\n",
    "\n",
    "df_all_years.to_csv(out_dir + 'fire_wind_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fire_lat_lon</th>\n",
       "      <th>ALARM_DATE</th>\n",
       "      <th>CONT_DATE</th>\n",
       "      <th>fire_centroid</th>\n",
       "      <th>GIS_ACRES</th>\n",
       "      <th>fire_wdir</th>\n",
       "      <th>fire_wspd</th>\n",
       "      <th>year_month</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7240</th>\n",
       "      <td>(37.74854288820926, -119.7035432531625)</td>\n",
       "      <td>2007-10-29</td>\n",
       "      <td>2007-12-08</td>\n",
       "      <td>POINT (-119.7035432531625 37.74854288820926)</td>\n",
       "      <td>239.260773</td>\n",
       "      <td>24.478956</td>\n",
       "      <td>0.169349</td>\n",
       "      <td>200710</td>\n",
       "      <td>2007</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7325</th>\n",
       "      <td>(37.74854288820926, -119.7035432531625)</td>\n",
       "      <td>2007-10-29</td>\n",
       "      <td>2007-12-08</td>\n",
       "      <td>POINT (-119.7035432531625 37.74854288820926)</td>\n",
       "      <td>239.260773</td>\n",
       "      <td>215.334213</td>\n",
       "      <td>0.138538</td>\n",
       "      <td>200711</td>\n",
       "      <td>2007</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7326</th>\n",
       "      <td>(37.74854288820926, -119.7035432531625)</td>\n",
       "      <td>2007-10-29</td>\n",
       "      <td>2007-12-08</td>\n",
       "      <td>POINT (-119.7035432531625 37.74854288820926)</td>\n",
       "      <td>239.260773</td>\n",
       "      <td>178.254211</td>\n",
       "      <td>0.474964</td>\n",
       "      <td>200712</td>\n",
       "      <td>2007</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 fire_lat_lon  ALARM_DATE   CONT_DATE  \\\n",
       "7240  (37.74854288820926, -119.7035432531625)  2007-10-29  2007-12-08   \n",
       "7325  (37.74854288820926, -119.7035432531625)  2007-10-29  2007-12-08   \n",
       "7326  (37.74854288820926, -119.7035432531625)  2007-10-29  2007-12-08   \n",
       "\n",
       "                                     fire_centroid   GIS_ACRES   fire_wdir  \\\n",
       "7240  POINT (-119.7035432531625 37.74854288820926)  239.260773   24.478956   \n",
       "7325  POINT (-119.7035432531625 37.74854288820926)  239.260773  215.334213   \n",
       "7326  POINT (-119.7035432531625 37.74854288820926)  239.260773  178.254211   \n",
       "\n",
       "      fire_wspd year_month  year month  \n",
       "7240   0.169349     200710  2007    10  \n",
       "7325   0.138538     200711  2007    11  \n",
       "7326   0.474964     200712  2007    12  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_years[df_all_years['fire_lat_lon'] == '(37.74854288820926, -119.7035432531625)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(35.25539508507167, -119.5812970773511)'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_years['fire_lat_lon'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
